{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U langchain-community\n",
    "# ! pip install chromadb\n",
    "# ! pip install openai\n",
    "# ! pip install langchain-chroma\n",
    "# ! pip install tiktoken\n",
    "# ! pip install faiss-cpu\n",
    "# ! pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data\"\n",
    "CHROMA_PATH = \"/Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    documents = document_loader.load()\n",
    "    print(f\"Loaded {len(documents)} documents.\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=80,length_function=len, is_separator_regex=False)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split into {len(chunks)} chunks.\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 documents.\n",
      "Split into 113 chunks.\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents()\n",
    "chunks = split_documents(documents)\n",
    "# print(chunks[0],\"\\nchunk1\\n\",chunks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "# from langchain_community.embeddings.bedrock import BedrockEmbeddings\n",
    "\n",
    "\n",
    "def get_embedding_function_ollama():\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"llama3\"\n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "def get_embedding_function_openai():\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        openai_api_key=\"ysk-dz6Xg-c4WLXHiRBsY8U9QpcTvr2-16Jd7QZcB2mlKPT3BlbkFJ-YQ_DlSzsDLNFbzM1YErPSxpUG-czmurGgdNVEMKoA\" \n",
    "    )\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x167805d60>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x167843ad0>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='ysk-dz6Xg-c4WLXHiRBsY8U9QpcTvr2-16Jd7QZcB2mlKPT3BlbkFJ-YQ_DlSzsDLNFbzM1YErPSxpUG-czmurGgdNVEMKoA', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding_function_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chunk_ids(chunks):\n",
    "\n",
    "    # This will create IDs like \"data/monopoly.pdf:6:2\"\n",
    "    # Page Source : Page Number : Chunk Index\n",
    "\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # If the page ID is the same as the last one, increment the index.\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        # Calculate the chunk ID.\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        # Add it to the page meta-data.\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_to_chroma(chunks: list[Document]):\n",
    "#     # Load the existing database.\n",
    "#     db = Chroma(\n",
    "#         persist_directory=CHROMA_PATH, embedding_function=get_embedding_function_ollama()\n",
    "#     )\n",
    "\n",
    "#     # Calculate Page IDs.\n",
    "#     chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "#     # Add or Update the documents.\n",
    "#     existing_items = db.get(include=[])  # IDs are always included by default\n",
    "#     existing_ids = set(existing_items[\"ids\"])\n",
    "#     print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "#     # Only add documents that don't exist in the DB.\n",
    "#     new_chunks = []\n",
    "#     for chunk in chunks_with_ids:\n",
    "#         if chunk.metadata[\"id\"] not in existing_ids:\n",
    "#             new_chunks.append(chunk)\n",
    "\n",
    "#     if len(new_chunks):\n",
    "#         print(f\"ðŸ‘‰ Adding new documents: {len(new_chunks)}\")\n",
    "#         new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "#         db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "#         db.persist()\n",
    "#     else:\n",
    "#         print(\"âœ… No new documents to add \\U0001F642\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    # Initialize Chroma vector store with embedding function\n",
    "    try:\n",
    "        embedding_function = get_embedding_function_openai()\n",
    "        db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "        print(f\"Chroma initialized successfully with embedding function from Ollama.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Chroma: {e}\")\n",
    "        return  # Stop if we cannot initialize the DB\n",
    "\n",
    "    # Check if chunks list is empty\n",
    "    if not chunks or len(chunks) == 0:\n",
    "        print(\"No document chunks to add to Chroma.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Attempting to add {len(chunks)} chunks to the Chroma database...\")\n",
    "\n",
    "    # Retrieve existing document IDs from the Chroma DB\n",
    "    try:\n",
    "        existing_items = db.get(include=[])  # IDs are always included by default\n",
    "        existing_ids = set(existing_items['ids'])  # Convert to set for fast lookup\n",
    "        print(f\"Total documents in DB before adding: {len(existing_ids)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving existing documents from Chroma: {e}\")\n",
    "        return\n",
    "\n",
    "    # Filter out chunks that are already in the database (by their 'id' metadata)\n",
    "    new_chunks = []\n",
    "    for chunk in chunks:\n",
    "        chunk_id = chunk.metadata.get(\"id\", None)  # Ensure the chunk has an ID\n",
    "        if chunk_id is not None and chunk_id not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "        else:\n",
    "            print(f\"Skipping duplicate chunk with ID: {chunk_id}\")\n",
    "\n",
    "    # Add new chunks to the Chroma database (if any)\n",
    "    if len(new_chunks) > 0:\n",
    "        try:\n",
    "            db.add_documents(new_chunks)\n",
    "            db.persist()  # Ensure the changes are persisted to disk\n",
    "            print(f\"Successfully added {len(new_chunks)} new chunks to Chroma.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding new chunks to Chroma: {e}\")\n",
    "    else:\n",
    "        print(\"No new chunks to add, all chunks already exist in the DB.\")\n",
    "\n",
    "    # Check the number of documents in the DB after adding\n",
    "    try:\n",
    "        existing_items = db.get(include=[])  # IDs are always included by default\n",
    "        print(f\"Total documents in DB after adding: {len(existing_items['ids'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving documents from Chroma after adding: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in DB: 226\n"
     ]
    }
   ],
   "source": [
    "def check_existing_documents():\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=get_embedding_function_openai())\n",
    "    existing_items = db.get(include=[])  # This retrieves all stored IDs\n",
    "    print(f\"Total documents in DB: {len(existing_items['ids'])}\")\n",
    "\n",
    "check_existing_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma initialized successfully with embedding function from Ollama.\n",
      "Attempting to add 113 chunks to the Chroma database...\n",
      "Total documents in DB before adding: 226\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:0:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:0:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:0:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:0:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:0:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:0:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:1:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:1:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:1:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:1:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:1:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:1:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:2:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:2:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:2:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:2:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:2:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:2:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:2:6\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:3:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:3:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:3:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:3:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:3:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:3:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:4:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:4:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:4:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:4:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:4:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:4:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:5:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:5:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:5:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:5:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:5:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:5:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:6:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:6:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:6:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:6:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:6:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:7:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:7:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:7:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:7:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:7:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:7:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:8:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:8:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:8:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/E17-1033.pdf:8:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:0:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:0:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:0:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:0:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:0:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:0:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:1:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:1:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:1:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:1:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:1:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:1:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:1:6\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:2:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:2:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:2:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:2:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:2:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:3:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:3:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:3:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:3:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:3:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:3:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:4:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:4:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:4:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:4:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:4:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:5:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:5:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:5:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:5:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:5:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:6:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:6:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:6:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:6:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:6:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:7:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:7:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:7:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:7:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:7:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:7:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:8:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:8:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:8:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:8:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:9:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:9:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:9:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:9:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:9:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:9:5\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:10:0\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:10:1\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:10:2\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:10:3\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:10:4\n",
      "Skipping duplicate chunk with ID: /Users/atreyeemukherjee/Library/Mobile Documents/com~apple~CloudDocs/side projects/data/W18-4102.pdf:10:5\n",
      "No new chunks to add, all chunks already exist in the DB.\n",
      "Total documents in DB after adding: 226\n"
     ]
    }
   ],
   "source": [
    "chunks = calculate_chunk_ids(chunks)\n",
    "add_to_chroma(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "\n",
    "FAISS_PATH = \"faiss_index\"\n",
    "\n",
    "def add_to_faiss(chunks: list):\n",
    "    # Load or create the FAISS index.\n",
    "    if os.path.exists(FAISS_PATH):\n",
    "        with open(FAISS_PATH, \"rb\") as f:\n",
    "            db = pickle.load(f)\n",
    "        print(\"Loaded existing FAISS index.\")\n",
    "    else:\n",
    "        db = FAISS(embedding_function=get_embedding_function_openai())\n",
    "        print(\"Created a new FAISS index.\")\n",
    "\n",
    "    # Add documents to the FAISS index\n",
    "    print(f\"ðŸ‘‰ Adding new documents: {len(chunks)}\")\n",
    "    db.add_documents(chunks)\n",
    "    \n",
    "    # Persist the FAISS index by saving it as a file\n",
    "    with open(FAISS_PATH, \"wb\") as f:\n",
    "        pickle.dump(db, f)\n",
    "    print(\"FAISS index updated and saved. \\U0001F642\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: ysk-dz6X************************************************************************************MKoA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response_text\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[120], line 30\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m args \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_args()\n\u001b[1;32m     29\u001b[0m query_text \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mquery_text\n\u001b[0;32m---> 30\u001b[0m \u001b[43mquery_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[120], line 39\u001b[0m, in \u001b[0;36mquery_rag\u001b[0;34m(query_text)\u001b[0m\n\u001b[1;32m     36\u001b[0m db \u001b[38;5;241m=\u001b[39m Chroma(persist_directory\u001b[38;5;241m=\u001b[39mCHROMA_PATH, embedding_function\u001b[38;5;241m=\u001b[39membedding_function)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Search the DB.\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo documents retrieved.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/documentqa/lib/python3.12/site-packages/langchain_community/vectorstores/chroma.py:439\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[0;34m(self, query, k, filter, where_document, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[1;32m    432\u001b[0m         query_texts\u001b[38;5;241m=\u001b[39m[query],\n\u001b[1;32m    433\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    437\u001b[0m     )\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__query_collection(\n\u001b[1;32m    441\u001b[0m         query_embeddings\u001b[38;5;241m=\u001b[39m[query_embedding],\n\u001b[1;32m    442\u001b[0m         n_results\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/documentqa/lib/python3.12/site-packages/langchain_community/embeddings/openai.py:700\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    692\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding query text.\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;124;03m        Embedding for the text.\u001b[39;00m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/documentqa/lib/python3.12/site-packages/langchain_community/embeddings/openai.py:671\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    670\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/documentqa/lib/python3.12/site-packages/langchain_community/embeddings/openai.py:497\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    495\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[0;32m--> 497\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43membed_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_chunk_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invocation_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    503\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdict()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/documentqa/lib/python3.12/site-packages/langchain_community/embeddings/openai.py:120\u001b[0m, in \u001b[0;36membed_with_retry\u001b[0;34m(embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the embedding call.\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(embeddings)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/documentqa/lib/python3.12/site-packages/openai/resources/embeddings.py:124\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    119\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/documentqa/lib/python3.12/site-packages/openai/_base_client.py:1270\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1258\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1265\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1267\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1268\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1269\u001b[0m     )\n\u001b[0;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/documentqa/lib/python3.12/site-packages/openai/_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/documentqa/lib/python3.12/site-packages/openai/_base_client.py:1051\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1050\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1054\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1055\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1060\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ysk-dz6X************************************************************************************MKoA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "\n",
    "# from get_embedding_function import get_embedding_function\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create CLI.\n",
    "    # \n",
    "    sys.argv = [\"ipykernel_launcher.py\", \"POS tagging definition\"]\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"query_text\", type=str, help=\"The query text.\")\n",
    "    args = parser.parse_args()\n",
    "    query_text = args.query_text\n",
    "    query_rag(query_text)\n",
    "\n",
    "\n",
    "def query_rag(query_text: str):\n",
    "    # Prepare the DB.\n",
    "    embedding_function = get_embedding_function_openai()\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "    if not results:\n",
    "        print(\"No documents retrieved.\")\n",
    "        return \"No relevant documents found.\"\n",
    "\n",
    "    for doc, score in results:\n",
    "        print(f\"Document Metadata: {doc.metadata}\")\n",
    "        print(f\"Similarity Score: {score}\")\n",
    "        print(f\"Document Content: {doc.page_content[:500]}\\n\")  # Print the first 500 characters\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    # print(prompt)\n",
    "\n",
    "    model = Ollama(model=\"llama3\")\n",
    "    response_text = model.invoke(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    print(formatted_response)\n",
    "    return response_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def query_rag(query_text: str):\n",
    "#     # Prepare the DB.\n",
    "#     embedding_function = get_embedding_function_ollama()\n",
    "#     db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "#     # Debug: Check if documents are in the database\n",
    "#     existing_items = db.get(include=[])  # IDs are always included by default\n",
    "#     print(f\"Total documents in DB: {len(existing_items['ids'])}\")\n",
    "\n",
    "#     # Search the DB.\n",
    "#     results = db.similarity_search_with_score(query_text, k=5)\n",
    "\n",
    "#     if not results:\n",
    "#         print(\"No documents retrieved.\")\n",
    "#         return \"No relevant documents found.\"\n",
    "\n",
    "#     # Display results for debugging\n",
    "#     for doc, score in results:\n",
    "#         print(f\"Document Metadata: {doc.metadata}\")\n",
    "#         print(f\"Similarity Score: {score}\")\n",
    "#         print(f\"Document Content: {doc.page_content[:500]}\\n\")  # Print the first 500 characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in DB: 0\n",
      "No documents retrieved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No relevant documents found.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_rag(\"POS tagging definition\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "documentqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
